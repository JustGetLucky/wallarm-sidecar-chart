# Wallarm sidecar controller
{{ template "chart.description" . }}

## Introduction
Wallarm sidecar controller provides an ability to automatically inject Wallarm sidecar proxy into a Kubernetes Pod.
Sidecar proxy filters and protects inbound traffic to the Pod it is attached to.

Components of Wallarm sidecar controller:
- Sidecar injector - is the mutating admission webhook which injects Wallarm sidecar proxy into Pods and provides configuration based on labels and annotations.
- Post-analytics module - is the local data analytics backend for Wallarm sidecar proxies. Implemented using Tarantool and set of helper containers.

## Prerequisites
- Kubernetes cluster >= 1.19-1.23
- Helm 3 package manager
- Access to Wallarm API endpoint:
    - `https://api.wallarm.com:443` for EU cloud
    - `https://us1.api.wallarm.com:443` for US cloud
- Access to Wallarm helm charts `https://charts.wallarm.com`
- Access to Wallarm repositories on Docker hub `https://hub.docker.com/r/wallarm`
- Wallarm node token created in Wallarm console. Refer [this manual](https://docs.wallarm.com/admin-en/installation-kubernetes-en/#step-1-installing-the-wallarm-ingress-controller)

## Installation
### Add repository
```
helm repo add wallarm https://charts.wallarm.com
helm repo update
```
### Install the chart
EU cloud
```
helm install wallarm-sidecar wallarm/wallarm-sidecar -n wallarm-sidecar --create-namespace --wait --set wallarmApi.token <API_TOKEN>
```
US cloud
```
helm install wallarm-sidecar wallarm/wallarm-sidecar -n wallarm-sidecar --create-namespace --wait --set wallarmApi.token <API_TOKEN> --set wallarmApi.host us1.api.wallarm.com
```
Where `<API_TOKEN>` is the Wallarm node token

## Usage
### Sidecar injection logic
Sidecar injection is controlled on a per-pod basis, by configuring the `wallarm-sidecar` label on a pod.

| Label           | Enabled value | Disabled value |
| --------------- | ------------- | -------------- |
| wallarm-sidecar | enabled       | disabled       |

Sidecar injection has the following logic:
1. If label is set to `enabled`, sidecar is injected
2. If label is set to `disabled`, sidecar is not injected
3. If label is not present in Pod spec, sidecar is not injected

Below is simple example of Kubernetes Deployment which has Wallarm sidecar enabled:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
        wallarm-sidecar: enabled
    spec:
      containers:
        - name: application
          image: mockserver/mockserver
          env:
            - name: MOCKSERVER_SERVER_PORT
              value: 80
          ports:
            - name: http
              containerPort: 80
```

### Application container port auto-discovery
In order to redirect and proxying incoming traffic properly, sidecar proxy must be aware about TCP port
on which application container accepts incoming requests. Application port auto-discovery has the following logic:
1. If pod has only one container port, this port will be used
2. If pod has multiple container ports:
   - If port with `name: http` found, number of his port will be used
   - If no any port has `name: http`, number of first port will be used
3. If pod has no container ports described, then default setting from `.Values.SidecarDefaults.nginx.proxyPassPort` will be used
4. If annotation `sidecar.wallarm.io/nginx-proxy-pass-port` is set, then it will take precedence over all options above

### Inbound traffic interception
By default Wallarm sidecar intercepts inbound traffic which comes to Pod's IP and application port, then redirects this
traffic to sidecar proxy container. Sidecar proxy does the job and then proxies traffic to application container.
Inbound traffic interception is implemented using `iptables` init container. This default behaviour can be disabled:
- on per-pod basis by setting Pod's annotation `sidecar.wallarm.io/sidecar-iptables-enable` to `"false"`
- globally by setting helm chart value `.Values.sidecarDefaults.deployment.iptablesEnable` to `"false"`

If inbound traffic interception is disabled, then sidecar proxy container will publish port with name `proxy`. In this case
inbound traffic from Kubernetes service should be sent to `proxy` port, by setting `spec.ports.targetPort: proxy`.
Below is an example with disabled inbound traffic interception on per-pod basis:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
        wallarm-sidecar: enabled
      annotations:
        sidecar.wallarm.io/sidecar-iptables-enable: "false"
    spec:
      containers:
        - name: application
          image: mockserver/mockserver
          env:
            - name: MOCKSERVER_SERVER_PORT
              value: 80
          ports:
            - name: http
              containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: myapp-svc
  namespace: default
spec:
  ports:
    - port: 80
      targetPort: proxy
      protocol: TCP
      name: http
  selector:
    app: myapp
```

### Enable additional Nginx modules
Docker image of sidecar proxy contains the following additional Nginx modules, which are disabled by default:
1. ngx_http_auth_digest_module.so
2. ngx_http_brotli_filter_module.so
3. ngx_http_brotli_static_module.so
4. ngx_http_geoip2_module.so
5. ngx_http_influxdb_module.so
6. ngx_http_modsecurity_module.so
7. ngx_http_opentracing_module.so
8. ngx_stream_geoip2_module.so

Enabling of these additional modules can be done on per-pod basis by setting Pod's annotation `sidecar.wallarm.io/nginx-extra-modules`.
The format of annotation's value is JSON list. Example with additional modules enabled is shown below:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
        wallarm-sidecar: enabled
      annotations:
        sidecar.wallarm.io/nginx-extra-modules: "['ngx_http_brotli_filter_module.so','ngx_http_brotli_static_module.so', 'ngx_http_opentracing_module.so']"
    spec:
      containers:
        - name: application
          image: mockserver/mockserver
          env:
            - name: MOCKSERVER_SERVER_PORT
              value: 80
          ports:
            - name: http
              containerPort: 80
```

### Using additional user provided Nginx configuration
Here is an option to include user provided configuration into Nginx config of sidecar proxy.
Additional configuration can be included on 3 different levels of Nginx config on per-pod basis using annotations.
The format of annotation's value is JSON list.

| Level of Nginx config  | Pod's annotation                           |
| ---------------------- | ------------------------------------------ |
| http                   | `sidecar.wallarm.io/nginx-http-include`    |
| server                 | `sidecar.wallarm.io/nginx-server-include`  |
| location               | `sidecar.wallarm.io/nginx-location-include`|

Providing additional configuration files achieves by using Volumes and Volumes mounts. Below is an example with
additional user provided configuration file which includes on `server` level of Nginx config:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
        wallarm-sidecar: enabled
      annotations:
        sidecar.wallarm.io/proxy-extra-volumes: '[{"name": "nginx-http-extra-config", "configMap": {"name": "nginx-include-cm"}}]'
        sidecar.wallarm.io/proxy-extra-volume-mounts: '[{"name": "nginx-http-extra-config", "mountPath": "/nginx_include/http.conf", "subPath": "http.conf"}]'
        sidecar.wallarm.io/nginx-http-include: "['/nginx_include/http.conf']"
            spec:
      containers:
        - name: application
          image: mockserver/mockserver
          env:
            - name: MOCKSERVER_SERVER_PORT
              value: 80
          ports:
            - name: http
              containerPort: 80
```

{{ template "chart.valuesSection" . }}
{{ template "helm-docs.versionFooter" . }}